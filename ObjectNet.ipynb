{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#from assets.keras.keras.datasets import shapes_3d\n",
    "from assets.keras.keras.preprocessing.image import ImageDataGenerator\n",
    "from assets.keras.keras.models import Sequential\n",
    "from assets.keras.keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from assets.keras.keras.layers.convolutional import Convolution3D, MaxPooling3D, ZeroPadding3D\n",
    "from assets.keras.keras.optimizers import SGD, Adam\n",
    "from assets.keras.keras.utils import np_utils, generic_utils\n",
    "from assets.keras.keras.regularizers import l2\n",
    "import theano\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#load dataset from gen_dataset\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (36, 1, 16, 32, 32)\n",
      "Train labels shape:  (36, 7)\n",
      "Test data shape:  (4, 1, 16, 32, 32)\n",
      "Test labels shape:  (4, 7)\n"
     ]
    }
   ],
   "source": [
    "from assets.gen_motion import gen_dataset\n",
    "import math\n",
    "#gen_dataset(size, N, obj_type, obj_theta, obj_vel, types, velocity, theta, coherence, dots)\n",
    "X_train1,Y_train1,X_test1,Y_test1 = gen_dataset((16,32,32),20,'square', (5,5,0), 0, 1,['translate'],[1],[0],[0],[150],[0])\n",
    "X_train2,Y_train2,X_test2,Y_test2 = gen_dataset((16,32,32),20,'circle', (5,5,0), 0, 1,['translate'],[1],[0],[0],[150],[0])\n",
    "\n",
    "X_train = np.concatenate((X_train1,X_train2),axis=0)\n",
    "Y_train = np.concatenate((Y_train1,Y_train2))\n",
    "X_test = np.concatenate((X_test1,X_test2))\n",
    "Y_test = np.concatenate((Y_test1,Y_test2))\n",
    "\n",
    "print 'Train data shape: ', X_train.shape\n",
    "print 'Train labels shape: ', Y_train.shape\n",
    "print 'Test data shape: ', X_test.shape\n",
    "print 'Test labels shape: ', Y_test.shape\n",
    "\n",
    "###\n",
    "#X_train = X_train[0:200,:,:,:,:]\n",
    "#Y_train = Y_train[0:200]\n",
    "#X_val = X_val[0:40,:,:,:,:]\n",
    "#Y_val = Y_val[0:40]\n",
    "# convert class vectors to binary class matrices\n",
    "\n",
    "#Y_train/=math.pi\n",
    "#Y_test/=math.pi\n",
    "Y_train = np_utils.to_categorical(Y_train[:,6]-1, 2)\n",
    "Y_test = np_utils.to_categorical(Y_test[:,6]-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train shape:', (36, 1, 16, 32, 32))\n",
      "('Y_train shape:', (36, 2))\n",
      "('X_test shape:', (4, 1, 16, 32, 32))\n",
      "('Y_test shape:', (4, 2))\n",
      "(36, 'train samples')\n",
      "(4, 'test samples')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('Y_test shape:', Y_test.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32 samples, validate on 4 samples\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s - loss: 0.4464 - acc: 0.5000 - val_loss: 0.3869 - val_acc: 0.5000\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s - loss: 0.3180 - acc: 0.6250 - val_loss: 0.5175 - val_acc: 0.5000\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s - loss: 0.2952 - acc: 0.6250 - val_loss: 0.5565 - val_acc: 0.5000\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s - loss: 0.2684 - acc: 0.6562 - val_loss: 0.5634 - val_acc: 0.2500\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s - loss: 0.2505 - acc: 0.7188 - val_loss: 0.5636 - val_acc: 0.2500\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s - loss: 0.2469 - acc: 0.7812 - val_loss: 0.5638 - val_acc: 0.2500\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s - loss: 0.2448 - acc: 0.7812 - val_loss: 0.5640 - val_acc: 0.2500\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s - loss: 0.2549 - acc: 0.7500 - val_loss: 0.5640 - val_acc: 0.2500\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s - loss: 0.2166 - acc: 0.8125 - val_loss: 0.5621 - val_acc: 0.2500\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s - loss: 0.2129 - acc: 0.8125 - val_loss: 0.5392 - val_acc: 0.5000\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s - loss: 0.2132 - acc: 0.8125 - val_loss: 0.5135 - val_acc: 0.5000\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s - loss: 0.2123 - acc: 0.8125 - val_loss: 0.5069 - val_acc: 0.5000\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s - loss: 0.2119 - acc: 0.8125 - val_loss: 0.5067 - val_acc: 0.5000\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s - loss: 0.1880 - acc: 0.8438 - val_loss: 0.5055 - val_acc: 0.5000\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s - loss: 0.1877 - acc: 0.8438 - val_loss: 0.5046 - val_acc: 0.5000\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s - loss: 0.1875 - acc: 0.8438 - val_loss: 0.5038 - val_acc: 0.5000\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s - loss: 0.1873 - acc: 0.8438 - val_loss: 0.5032 - val_acc: 0.5000\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s - loss: 0.1859 - acc: 0.8750 - val_loss: 0.4992 - val_acc: 0.5000\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s - loss: 0.1826 - acc: 0.8438 - val_loss: 0.5000 - val_acc: 0.5000\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s - loss: 0.1781 - acc: 0.8750 - val_loss: 0.5015 - val_acc: 0.5000\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s - loss: 0.1778 - acc: 0.8750 - val_loss: 0.5043 - val_acc: 0.5000\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s - loss: 0.1776 - acc: 0.8750 - val_loss: 0.5086 - val_acc: 0.5000\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s - loss: 0.1773 - acc: 0.8750 - val_loss: 0.5144 - val_acc: 0.5000\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s - loss: 0.1770 - acc: 0.8750 - val_loss: 0.5214 - val_acc: 0.5000\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s - loss: 0.1767 - acc: 0.8750 - val_loss: 0.5290 - val_acc: 0.5000\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s - loss: 0.1764 - acc: 0.8750 - val_loss: 0.5368 - val_acc: 0.5000\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s - loss: 0.1762 - acc: 0.8750 - val_loss: 0.5446 - val_acc: 0.5000\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s - loss: 0.1759 - acc: 0.8750 - val_loss: 0.5518 - val_acc: 0.5000\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s - loss: 0.1756 - acc: 0.8750 - val_loss: 0.5585 - val_acc: 0.5000\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s - loss: 0.1753 - acc: 0.8750 - val_loss: 0.5644 - val_acc: 0.2500\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s - loss: 0.1750 - acc: 0.8750 - val_loss: 0.5693 - val_acc: 0.2500\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s - loss: 0.1748 - acc: 0.8750 - val_loss: 0.5695 - val_acc: 0.2500\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s - loss: 0.1745 - acc: 0.8750 - val_loss: 0.5696 - val_acc: 0.2500\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s - loss: 0.1742 - acc: 0.8750 - val_loss: 0.5698 - val_acc: 0.2500\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s - loss: 0.1740 - acc: 0.8750 - val_loss: 0.5700 - val_acc: 0.2500\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s - loss: 0.1737 - acc: 0.8750 - val_loss: 0.5701 - val_acc: 0.2500\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s - loss: 0.1735 - acc: 0.8750 - val_loss: 0.5703 - val_acc: 0.2500\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s - loss: 0.1732 - acc: 0.8750 - val_loss: 0.5705 - val_acc: 0.2500\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s - loss: 0.1729 - acc: 0.8750 - val_loss: 0.5706 - val_acc: 0.2500\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s - loss: 0.1727 - acc: 0.8750 - val_loss: 0.5707 - val_acc: 0.2500\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s - loss: 0.1724 - acc: 0.8750 - val_loss: 0.5708 - val_acc: 0.2500\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s - loss: 0.1722 - acc: 0.8750 - val_loss: 0.5709 - val_acc: 0.2500\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s - loss: 0.1719 - acc: 0.8750 - val_loss: 0.5710 - val_acc: 0.2500\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s - loss: 0.1716 - acc: 0.8750 - val_loss: 0.5711 - val_acc: 0.2500\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s - loss: 0.1714 - acc: 0.8750 - val_loss: 0.5712 - val_acc: 0.2500\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s - loss: 0.1712 - acc: 0.8750 - val_loss: 0.5713 - val_acc: 0.2500\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s - loss: 0.1709 - acc: 0.8750 - val_loss: 0.5714 - val_acc: 0.2500\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s - loss: 0.1706 - acc: 0.8750 - val_loss: 0.5714 - val_acc: 0.2500\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s - loss: 0.1705 - acc: 0.8750 - val_loss: 0.5715 - val_acc: 0.2500\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s - loss: 0.1702 - acc: 0.8750 - val_loss: 0.5717 - val_acc: 0.2500\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s - loss: 0.1700 - acc: 0.8750 - val_loss: 0.5718 - val_acc: 0.2500\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s - loss: 0.1697 - acc: 0.8750 - val_loss: 0.5720 - val_acc: 0.2500\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s - loss: 0.1695 - acc: 0.8750 - val_loss: 0.5721 - val_acc: 0.2500\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s - loss: 0.1693 - acc: 0.8750 - val_loss: 0.5722 - val_acc: 0.2500\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s - loss: 0.1690 - acc: 0.8750 - val_loss: 0.5723 - val_acc: 0.2500\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s - loss: 0.1688 - acc: 0.8750 - val_loss: 0.5724 - val_acc: 0.2500\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s - loss: 0.1686 - acc: 0.8750 - val_loss: 0.5724 - val_acc: 0.2500\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s - loss: 0.1684 - acc: 0.8750 - val_loss: 0.5725 - val_acc: 0.2500\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s - loss: 0.1682 - acc: 0.8750 - val_loss: 0.5726 - val_acc: 0.2500\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s - loss: 0.1679 - acc: 0.8750 - val_loss: 0.5726 - val_acc: 0.2500\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s - loss: 0.1677 - acc: 0.8750 - val_loss: 0.5727 - val_acc: 0.2500\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s - loss: 0.1675 - acc: 0.8750 - val_loss: 0.5728 - val_acc: 0.2500\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s - loss: 0.1673 - acc: 0.8750 - val_loss: 0.5727 - val_acc: 0.2500\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s - loss: 0.1671 - acc: 0.8750 - val_loss: 0.5727 - val_acc: 0.2500\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s - loss: 0.1668 - acc: 0.8750 - val_loss: 0.5726 - val_acc: 0.2500\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s - loss: 0.1666 - acc: 0.8750 - val_loss: 0.5726 - val_acc: 0.2500\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s - loss: 0.1665 - acc: 0.8750 - val_loss: 0.5727 - val_acc: 0.2500\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s - loss: 0.1662 - acc: 0.8750 - val_loss: 0.5725 - val_acc: 0.2500\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s - loss: 0.1660 - acc: 0.8750 - val_loss: 0.5724 - val_acc: 0.2500\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s - loss: 0.1658 - acc: 0.8750 - val_loss: 0.5724 - val_acc: 0.2500\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s - loss: 0.1656 - acc: 0.8750 - val_loss: 0.5721 - val_acc: 0.2500\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s - loss: 0.1654 - acc: 0.8750 - val_loss: 0.5719 - val_acc: 0.2500\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s - loss: 0.1652 - acc: 0.8750 - val_loss: 0.5714 - val_acc: 0.2500\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s - loss: 0.1650 - acc: 0.8750 - val_loss: 0.5705 - val_acc: 0.2500\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s - loss: 0.1648 - acc: 0.8750 - val_loss: 0.5691 - val_acc: 0.2500\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s - loss: 0.1646 - acc: 0.8750 - val_loss: 0.5676 - val_acc: 0.2500\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s - loss: 0.1644 - acc: 0.8750 - val_loss: 0.5660 - val_acc: 0.2500\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s - loss: 0.1642 - acc: 0.8750 - val_loss: 0.5623 - val_acc: 0.2500\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s - loss: 0.1640 - acc: 0.8750 - val_loss: 0.5568 - val_acc: 0.2500\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s - loss: 0.1638 - acc: 0.8750 - val_loss: 0.5495 - val_acc: 0.2500\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s - loss: 0.1635 - acc: 0.8750 - val_loss: 0.5322 - val_acc: 0.2500\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s - loss: 0.1633 - acc: 0.8750 - val_loss: 0.5030 - val_acc: 0.2500\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s - loss: 0.1632 - acc: 0.8750 - val_loss: 0.4514 - val_acc: 0.2500\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s - loss: 0.1627 - acc: 0.8750 - val_loss: 0.4179 - val_acc: 0.2500\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s - loss: 0.1420 - acc: 0.8750 - val_loss: 0.4183 - val_acc: 0.2500\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s - loss: 0.1418 - acc: 0.8750 - val_loss: 0.4188 - val_acc: 0.2500\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s - loss: 0.1417 - acc: 0.8750 - val_loss: 0.4193 - val_acc: 0.2500\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s - loss: 0.1416 - acc: 0.8750 - val_loss: 0.4198 - val_acc: 0.2500\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s - loss: 0.1414 - acc: 0.8750 - val_loss: 0.4202 - val_acc: 0.2500\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s - loss: 0.1412 - acc: 0.8750 - val_loss: 0.4207 - val_acc: 0.2500\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s - loss: 0.1411 - acc: 0.8750 - val_loss: 0.4211 - val_acc: 0.2500\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s - loss: 0.1409 - acc: 0.8750 - val_loss: 0.4216 - val_acc: 0.2500\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s - loss: 0.1408 - acc: 0.8750 - val_loss: 0.4220 - val_acc: 0.2500\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s - loss: 0.1407 - acc: 0.8750 - val_loss: 0.4224 - val_acc: 0.2500\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s - loss: 0.1405 - acc: 0.8750 - val_loss: 0.4228 - val_acc: 0.2500\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s - loss: 0.1404 - acc: 0.8750 - val_loss: 0.4232 - val_acc: 0.2500\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s - loss: 0.1403 - acc: 0.8750 - val_loss: 0.4237 - val_acc: 0.2500\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s - loss: 0.1401 - acc: 0.8750 - val_loss: 0.4241 - val_acc: 0.2500\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s - loss: 0.1400 - acc: 0.8750 - val_loss: 0.4245 - val_acc: 0.2500\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s - loss: 0.1399 - acc: 0.8750 - val_loss: 0.4249 - val_acc: 0.2500\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s - loss: 0.1397 - acc: 0.8750 - val_loss: 0.4253 - val_acc: 0.2500\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s - loss: 0.1396 - acc: 0.8750 - val_loss: 0.4258 - val_acc: 0.2500\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s - loss: 0.1395 - acc: 0.8750 - val_loss: 0.4262 - val_acc: 0.2500\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s - loss: 0.1393 - acc: 0.8750 - val_loss: 0.4266 - val_acc: 0.2500\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s - loss: 0.1392 - acc: 0.8750 - val_loss: 0.4270 - val_acc: 0.2500\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s - loss: 0.1391 - acc: 0.8750 - val_loss: 0.4275 - val_acc: 0.2500\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s - loss: 0.1390 - acc: 0.8750 - val_loss: 0.4279 - val_acc: 0.2500\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s - loss: 0.1388 - acc: 0.8750 - val_loss: 0.4283 - val_acc: 0.2500\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s - loss: 0.1387 - acc: 0.8750 - val_loss: 0.4287 - val_acc: 0.2500\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s - loss: 0.1386 - acc: 0.8750 - val_loss: 0.4291 - val_acc: 0.2500\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s - loss: 0.1385 - acc: 0.8750 - val_loss: 0.4296 - val_acc: 0.2500\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s - loss: 0.1383 - acc: 0.8750 - val_loss: 0.4300 - val_acc: 0.2500\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s - loss: 0.1382 - acc: 0.8750 - val_loss: 0.4304 - val_acc: 0.2500\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s - loss: 0.1381 - acc: 0.8750 - val_loss: 0.4308 - val_acc: 0.2500\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s - loss: 0.1380 - acc: 0.8750 - val_loss: 0.4312 - val_acc: 0.2500\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s - loss: 0.1378 - acc: 0.8750 - val_loss: 0.4316 - val_acc: 0.2500\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s - loss: 0.1377 - acc: 0.8750 - val_loss: 0.4321 - val_acc: 0.2500\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s - loss: 0.1376 - acc: 0.8750 - val_loss: 0.4325 - val_acc: 0.2500\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s - loss: 0.1375 - acc: 0.8750 - val_loss: 0.4329 - val_acc: 0.2500\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s - loss: 0.1374 - acc: 0.8750 - val_loss: 0.4333 - val_acc: 0.2500\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s - loss: 0.1373 - acc: 0.8750 - val_loss: 0.4337 - val_acc: 0.2500\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s - loss: 0.1372 - acc: 0.8750 - val_loss: 0.4341 - val_acc: 0.2500\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s - loss: 0.1370 - acc: 0.8750 - val_loss: 0.4345 - val_acc: 0.2500\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s - loss: 0.1369 - acc: 0.8750 - val_loss: 0.4349 - val_acc: 0.2500\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s - loss: 0.1368 - acc: 0.8750 - val_loss: 0.4353 - val_acc: 0.2500\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s - loss: 0.1367 - acc: 0.8750 - val_loss: 0.4356 - val_acc: 0.2500\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s - loss: 0.1366 - acc: 0.8750 - val_loss: 0.4360 - val_acc: 0.2500\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s - loss: 0.1365 - acc: 0.8750 - val_loss: 0.4364 - val_acc: 0.2500\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s - loss: 0.1363 - acc: 0.8750 - val_loss: 0.4368 - val_acc: 0.2500\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s - loss: 0.1363 - acc: 0.8750 - val_loss: 0.4372 - val_acc: 0.2500\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s - loss: 0.1362 - acc: 0.8750 - val_loss: 0.4376 - val_acc: 0.2500\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s - loss: 0.1360 - acc: 0.8750 - val_loss: 0.4380 - val_acc: 0.2500\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s - loss: 0.1359 - acc: 0.8750 - val_loss: 0.4384 - val_acc: 0.2500\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s - loss: 0.1358 - acc: 0.8750 - val_loss: 0.4388 - val_acc: 0.2500\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s - loss: 0.1357 - acc: 0.8750 - val_loss: 0.4392 - val_acc: 0.2500\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s - loss: 0.1356 - acc: 0.8750 - val_loss: 0.4396 - val_acc: 0.2500\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s - loss: 0.1355 - acc: 0.8750 - val_loss: 0.4400 - val_acc: 0.2500\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s - loss: 0.1354 - acc: 0.8750 - val_loss: 0.4404 - val_acc: 0.2500\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s - loss: 0.1353 - acc: 0.8750 - val_loss: 0.4408 - val_acc: 0.2500\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s - loss: 0.1352 - acc: 0.8750 - val_loss: 0.4412 - val_acc: 0.2500\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s - loss: 0.1351 - acc: 0.8750 - val_loss: 0.4416 - val_acc: 0.2500\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s - loss: 0.1349 - acc: 0.8750 - val_loss: 0.4420 - val_acc: 0.2500\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s - loss: 0.1348 - acc: 0.8750 - val_loss: 0.4424 - val_acc: 0.2500\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s - loss: 0.1347 - acc: 0.8750 - val_loss: 0.4428 - val_acc: 0.2500\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s - loss: 0.1346 - acc: 0.8750 - val_loss: 0.4432 - val_acc: 0.2500\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s - loss: 0.1346 - acc: 0.8750 - val_loss: 0.4437 - val_acc: 0.2500\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s - loss: 0.1344 - acc: 0.8750 - val_loss: 0.4441 - val_acc: 0.2500\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s - loss: 0.1343 - acc: 0.8750 - val_loss: 0.4445 - val_acc: 0.2500\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s - loss: 0.1342 - acc: 0.8750 - val_loss: 0.4449 - val_acc: 0.2500\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s - loss: 0.1341 - acc: 0.8750 - val_loss: 0.4453 - val_acc: 0.2500\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s - loss: 0.1340 - acc: 0.8750 - val_loss: 0.4457 - val_acc: 0.2500\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s - loss: 0.1339 - acc: 0.8750 - val_loss: 0.4461 - val_acc: 0.2500\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s - loss: 0.1338 - acc: 0.8750 - val_loss: 0.4465 - val_acc: 0.2500\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s - loss: 0.1337 - acc: 0.8750 - val_loss: 0.4469 - val_acc: 0.2500\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s - loss: 0.1336 - acc: 0.8750 - val_loss: 0.4473 - val_acc: 0.2500\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s - loss: 0.1335 - acc: 0.8750 - val_loss: 0.4478 - val_acc: 0.2500\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s - loss: 0.1334 - acc: 0.8750 - val_loss: 0.4482 - val_acc: 0.2500\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s - loss: 0.1333 - acc: 0.8750 - val_loss: 0.4486 - val_acc: 0.2500\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s - loss: 0.1331 - acc: 0.8750 - val_loss: 0.4490 - val_acc: 0.2500\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s - loss: 0.1331 - acc: 0.8750 - val_loss: 0.4495 - val_acc: 0.2500\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s - loss: 0.1329 - acc: 0.8750 - val_loss: 0.4499 - val_acc: 0.2500\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s - loss: 0.1329 - acc: 0.8750 - val_loss: 0.4503 - val_acc: 0.2500\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s - loss: 0.1328 - acc: 0.8750 - val_loss: 0.4507 - val_acc: 0.2500\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s - loss: 0.1327 - acc: 0.8750 - val_loss: 0.4511 - val_acc: 0.2500\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s - loss: 0.1326 - acc: 0.8750 - val_loss: 0.4515 - val_acc: 0.2500\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s - loss: 0.1325 - acc: 0.8750 - val_loss: 0.4519 - val_acc: 0.2500\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s - loss: 0.1324 - acc: 0.8750 - val_loss: 0.4522 - val_acc: 0.2500\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s - loss: 0.1323 - acc: 0.8750 - val_loss: 0.4526 - val_acc: 0.2500\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s - loss: 0.1322 - acc: 0.8750 - val_loss: 0.4529 - val_acc: 0.2500\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s - loss: 0.1321 - acc: 0.8750 - val_loss: 0.4532 - val_acc: 0.2500\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s - loss: 0.1321 - acc: 0.8750 - val_loss: 0.4536 - val_acc: 0.2500\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s - loss: 0.1320 - acc: 0.8750 - val_loss: 0.4539 - val_acc: 0.2500"
     ]
    }
   ],
   "source": [
    "\n",
    "# CNN Training parameters\n",
    "batch_size = 20\n",
    "nb_classes = 2\n",
    "nb_epoch = 200\n",
    "\n",
    "\n",
    "# number of convolutional filters to use at each layer\n",
    "nb_filters = [2,2,2]\n",
    "\n",
    "# level of pooling to perform at each layer (POOL x POOL)\n",
    "nb_pool = [2,2,2]\n",
    "\n",
    "# level of convolution to perform at each layer (CONV x CONV)\n",
    "nb_conv = [3,3,3]\n",
    "\n",
    "# Regularization\n",
    "reg = 1e-4\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(ZeroPadding3D((1,1,1),))\n",
    "model.add(Convolution3D(nb_filters[0],len_conv_dim1=nb_conv[0], len_conv_dim2=nb_conv[0], len_conv_dim3=nb_conv[0], border_mode='valid',\n",
    "                         activation='relu', W_regularizer=l2(reg),dim_ordering='th',input_shape=(1,16,32,32)))\n",
    "model.add(MaxPooling3D(pool_size=(1, nb_pool[0], nb_pool[0])))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(ZeroPadding3D((1,1,1)))\n",
    "model.add(Convolution3D(nb_filters[1],len_conv_dim1=nb_conv[1], len_conv_dim2=nb_conv[1], len_conv_dim3=nb_conv[1], border_mode='valid',\n",
    "                        activation='relu', W_regularizer=l2(reg)))\n",
    "#model.add(MaxPooling3D(pool_size=(nb_pool[1], nb_pool[1], nb_pool[1])))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(ZeroPadding3D((1,1,1)))\n",
    "model.add(Convolution3D(nb_filters[2],len_conv_dim1=nb_conv[1], len_conv_dim2=nb_conv[1], len_conv_dim3=nb_conv[1], border_mode='valid',\n",
    "                        activation='relu', W_regularizer=l2(reg)))\n",
    "model.add(Flatten())\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(4, init='normal', activation='relu', W_regularizer=l2(reg)))\n",
    "model.add(Dense(nb_classes, init='normal', W_regularizer=l2(reg)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#Adam\n",
    "sgd = Adam(lr=1e-3)#, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mse', optimizer=sgd)\n",
    "\n",
    "hist = model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, verbose=1,\n",
    "          validation_split=.1)\n",
    "scoretr = model.evaluate(X_train, Y_train, batch_size=batch_size, show_accuracy=True)\n",
    "#scoreva = model.evaluate(X_val, Y_val, batch_size=batch_size, show_accuracy=True)\n",
    "scorete = model.evaluate(X_test, Y_test, batch_size=batch_size, show_accuracy=True)\n",
    "print('Train loss:', scoretr[0])\n",
    "print('Train accuracy:', scoretr[1])\n",
    "#print('Val loss:', scoreva[0])\n",
    "#print('Val accuracy:', scoreva[1])\n",
    "print('Test loss:', scorete[0])\n",
    "print('Test accuracy:', scorete[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
